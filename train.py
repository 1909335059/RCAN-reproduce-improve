import torch
from torch.utils.data import DataLoader
import torch.nn as nn
from torch.optim import Adam
from tqdm import tqdm
from repreparing import SRDataset
from rcan import RCAN  # å¦‚æœæ˜¯ DenseRCAN å°±å†™ from rcan import DenseRCAN
from skimage.metrics import peak_signal_noise_ratio as psnr_metric
from skimage.metrics import structural_similarity as ssim_metric
import numpy as np

# ===================== è®¾ç½®å‚æ•° =====================
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
scale = 2
batch_size = 4
epochs = 150
lr = 1e-4

# æ•°æ®é›†è·¯å¾„ï¼ˆåªéœ€è¦ HR å›¾ï¼‰
hr_dir = "dataset/HR"

# ===================== æ•°æ®åŠ è½½ =====================
# è®­ç»ƒé›†
train_dataset = SRDataset(hr_dir, scale=scale)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# éªŒè¯é›†ï¼ˆè¿™é‡Œç®€å•ç”¨è®­ç»ƒé›†æ‹·è´ä¸€ä»½å½“éªŒè¯é›†ï¼Œä½ ä¹Ÿå¯ä»¥æ›¿æ¢æˆçœŸå®çš„éªŒè¯é›†ï¼‰
val_dataset = SRDataset(hr_dir, scale=scale)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)

# ===================== æ¨¡å‹ =====================
model = RCAN(n_resgroups=3, n_resblocks=5, n_feats=64, scale=scale).to(device)
# å¦‚æœæƒ³ç”¨ DenseRCANï¼š
# model = DenseRCAN(n_resgroups=3, n_resblocks=5, n_feats=64, scale=scale).to(device)

# ===================== æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨ =====================
criterion = nn.L1Loss()
optimizer = Adam(model.parameters(), lr=lr)

# ===================== è®¡ç®—è¯„ä»·æŒ‡æ ‡ =====================
def evaluate(model, dataloader):
    """åœ¨éªŒè¯é›†ä¸Šè®¡ç®— PSNR å’Œ SSIM"""
    model.eval()
    total_psnr, total_ssim, count = 0, 0, 0
    with torch.no_grad():
        for lr_imgs, hr_imgs in dataloader:
            lr_imgs = lr_imgs.to(device)
            hr_imgs = hr_imgs.to(device)

            sr_imgs = model(lr_imgs)  # è¶…åˆ†æ¨ç†

            # Tensor(C,H,W) -> Numpy(H,W,C)
            sr = sr_imgs.squeeze(0).permute(1, 2, 0).cpu().numpy()
            hr = hr_imgs.squeeze(0).permute(1, 2, 0).cpu().numpy()

            # ä¿è¯èŒƒå›´åœ¨ [0,1]
            sr = np.clip(sr, 0, 1)
            hr = np.clip(hr, 0, 1)

            # è®¡ç®— PSNR å’Œ SSIM
            psnr_val = psnr_metric(hr, sr, data_range=1.0)
            ssim_val = ssim_metric(hr, sr, data_range=1.0, channel_axis=2)

            total_psnr += psnr_val
            total_ssim += ssim_val
            count += 1

    return total_psnr / count, total_ssim / count

# ===================== è®­ç»ƒ =====================
best_psnr = 0

for epoch in range(epochs):
    model.train()
    epoch_loss = 0.0
    pbar = tqdm(train_loader, total=len(train_loader), desc=f"Epoch {epoch+1}/{epochs}")

    for batch in pbar:
        lr_imgs, hr_imgs = batch
        lr_imgs, hr_imgs = lr_imgs.to(device), hr_imgs.to(device)

        preds = model(lr_imgs)
        loss = criterion(preds, hr_imgs)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        epoch_loss += loss.item()
        pbar.set_postfix({"Loss": f"{loss.item():.4f}"})

    avg_loss = epoch_loss / len(train_loader)

    # ===== æ¯ä¸ª epoch ç»“æŸåè®¡ç®—éªŒè¯é›† PSNR/SSIM =====
    avg_psnr, avg_ssim = evaluate(model, val_loader)
    print(f"[Epoch {epoch+1}/{epochs}] Loss: {avg_loss:.4f} | PSNR: {avg_psnr:.4f} dB | SSIM: {avg_ssim:.4f}")

    # å¦‚æœ PSNR æ›´ä¼˜ï¼Œåˆ™ä¿å­˜æ¨¡å‹
    if avg_psnr > best_psnr:
        best_psnr = avg_psnr
        torch.save(model.state_dict(), "rcan_best.pth")
        print(f"ğŸ’¾ ä¿å­˜æœ€ä¼˜æ¨¡å‹ (PSNR={best_psnr:.4f} dB) -> rcan_best.pth")

print("âœ… è®­ç»ƒå®Œæˆ")
print(f"ğŸ† æœ€ä½³ PSNR: {best_psnr:.4f} dB å·²ä¿å­˜è‡³ rcan_best.pth")
